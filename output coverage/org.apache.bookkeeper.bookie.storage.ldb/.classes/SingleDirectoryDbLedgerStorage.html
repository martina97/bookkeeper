


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: SingleDirectoryDbLedgerStorage</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">org.apache.bookkeeper.bookie.storage.ldb</a> ]
</div>

<h1>Coverage Summary for Class: SingleDirectoryDbLedgerStorage (org.apache.bookkeeper.bookie.storage.ldb)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">SingleDirectoryDbLedgerStorage</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 54)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 375)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/**
<i>2</i>&nbsp; *
<i>3</i>&nbsp; * Licensed to the Apache Software Foundation (ASF) under one
<i>4</i>&nbsp; * or more contributor license agreements.  See the NOTICE file
<i>5</i>&nbsp; * distributed with this work for additional information
<i>6</i>&nbsp; * regarding copyright ownership.  The ASF licenses this file
<i>7</i>&nbsp; * to you under the Apache License, Version 2.0 (the
<i>8</i>&nbsp; * &quot;License&quot;); you may not use this file except in compliance
<i>9</i>&nbsp; * with the License.  You may obtain a copy of the License at
<i>10</i>&nbsp; *
<i>11</i>&nbsp; *   http://www.apache.org/licenses/LICENSE-2.0
<i>12</i>&nbsp; *
<i>13</i>&nbsp; * Unless required by applicable law or agreed to in writing,
<i>14</i>&nbsp; * software distributed under the License is distributed on an
<i>15</i>&nbsp; * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
<i>16</i>&nbsp; * KIND, either express or implied.  See the License for the
<i>17</i>&nbsp; * specific language governing permissions and limitations
<i>18</i>&nbsp; * under the License.
<i>19</i>&nbsp; *
<i>20</i>&nbsp; */
<i>21</i>&nbsp;package org.apache.bookkeeper.bookie.storage.ldb;
<i>22</i>&nbsp;
<i>23</i>&nbsp;import static com.google.common.base.Preconditions.checkArgument;
<i>24</i>&nbsp;
<i>25</i>&nbsp;import com.google.common.annotations.VisibleForTesting;
<i>26</i>&nbsp;import com.google.common.collect.Lists;
<i>27</i>&nbsp;import com.google.protobuf.ByteString;
<i>28</i>&nbsp;
<i>29</i>&nbsp;import io.netty.buffer.ByteBuf;
<i>30</i>&nbsp;import io.netty.buffer.ByteBufAllocator;
<i>31</i>&nbsp;import io.netty.util.concurrent.DefaultThreadFactory;
<i>32</i>&nbsp;
<i>33</i>&nbsp;import java.io.IOException;
<i>34</i>&nbsp;import java.util.Collections;
<i>35</i>&nbsp;import java.util.List;
<i>36</i>&nbsp;import java.util.PrimitiveIterator.OfLong;
<i>37</i>&nbsp;import java.util.concurrent.CopyOnWriteArrayList;
<i>38</i>&nbsp;import java.util.concurrent.ExecutorService;
<i>39</i>&nbsp;import java.util.concurrent.Executors;
<i>40</i>&nbsp;import java.util.concurrent.ScheduledExecutorService;
<i>41</i>&nbsp;import java.util.concurrent.TimeUnit;
<i>42</i>&nbsp;import java.util.concurrent.atomic.AtomicBoolean;
<i>43</i>&nbsp;import java.util.concurrent.locks.ReentrantLock;
<i>44</i>&nbsp;import java.util.concurrent.locks.StampedLock;
<i>45</i>&nbsp;
<i>46</i>&nbsp;import org.apache.bookkeeper.bookie.Bookie;
<i>47</i>&nbsp;import org.apache.bookkeeper.bookie.Bookie.NoEntryException;
<i>48</i>&nbsp;import org.apache.bookkeeper.bookie.BookieException;
<i>49</i>&nbsp;import org.apache.bookkeeper.bookie.BookieException.OperationRejectedException;
<i>50</i>&nbsp;import org.apache.bookkeeper.bookie.CheckpointSource;
<i>51</i>&nbsp;import org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint;
<i>52</i>&nbsp;import org.apache.bookkeeper.bookie.Checkpointer;
<i>53</i>&nbsp;import org.apache.bookkeeper.bookie.CompactableLedgerStorage;
<i>54</i>&nbsp;import org.apache.bookkeeper.bookie.EntryLocation;
<i>55</i>&nbsp;import org.apache.bookkeeper.bookie.EntryLogger;
<i>56</i>&nbsp;import org.apache.bookkeeper.bookie.GarbageCollectionStatus;
<i>57</i>&nbsp;import org.apache.bookkeeper.bookie.GarbageCollectorThread;
<i>58</i>&nbsp;import org.apache.bookkeeper.bookie.LastAddConfirmedUpdateNotification;
<i>59</i>&nbsp;import org.apache.bookkeeper.bookie.LedgerCache;
<i>60</i>&nbsp;import org.apache.bookkeeper.bookie.LedgerDirsManager;
<i>61</i>&nbsp;import org.apache.bookkeeper.bookie.LedgerEntryPage;
<i>62</i>&nbsp;import org.apache.bookkeeper.bookie.StateManager;
<i>63</i>&nbsp;import org.apache.bookkeeper.bookie.storage.ldb.DbLedgerStorageDataFormats.LedgerData;
<i>64</i>&nbsp;import org.apache.bookkeeper.bookie.storage.ldb.KeyValueStorage.Batch;
<i>65</i>&nbsp;import org.apache.bookkeeper.common.util.Watcher;
<i>66</i>&nbsp;import org.apache.bookkeeper.conf.ServerConfiguration;
<i>67</i>&nbsp;import org.apache.bookkeeper.meta.LedgerManager;
<i>68</i>&nbsp;import org.apache.bookkeeper.proto.BookieProtocol;
<i>69</i>&nbsp;import org.apache.bookkeeper.stats.OpStatsLogger;
<i>70</i>&nbsp;import org.apache.bookkeeper.stats.StatsLogger;
<i>71</i>&nbsp;import org.apache.bookkeeper.util.MathUtils;
<i>72</i>&nbsp;import org.apache.bookkeeper.util.collections.ConcurrentLongHashMap;
<i>73</i>&nbsp;import org.apache.commons.lang.mutable.MutableLong;
<i>74</i>&nbsp;import org.slf4j.Logger;
<i>75</i>&nbsp;import org.slf4j.LoggerFactory;
<i>76</i>&nbsp;
<i>77</i>&nbsp;/**
<i>78</i>&nbsp; * Single directory implementation of LedgerStorage that uses RocksDB to keep the indexes for entries stored in
<i>79</i>&nbsp; * EntryLogs.
<i>80</i>&nbsp; *
<i>81</i>&nbsp; * &lt;p&gt;This is meant only to be used from {@link DbLedgerStorage}.
<i>82</i>&nbsp; */
<i>83</i>&nbsp;public class SingleDirectoryDbLedgerStorage implements CompactableLedgerStorage {
<i>84</i>&nbsp;    private final EntryLogger entryLogger;
<i>85</i>&nbsp;
<i>86</i>&nbsp;    private final LedgerMetadataIndex ledgerIndex;
<i>87</i>&nbsp;    private final EntryLocationIndex entryLocationIndex;
<i>88</i>&nbsp;
<i>89</i>&nbsp;    private final ConcurrentLongHashMap&lt;TransientLedgerInfo&gt; transientLedgerInfoCache;
<i>90</i>&nbsp;
<i>91</i>&nbsp;    private final GarbageCollectorThread gcThread;
<i>92</i>&nbsp;
<i>93</i>&nbsp;    // Write cache where all new entries are inserted into
<i>94</i>&nbsp;    protected volatile WriteCache writeCache;
<i>95</i>&nbsp;
<i>96</i>&nbsp;    // Write cache that is used to swap with writeCache during flushes
<i>97</i>&nbsp;    protected volatile WriteCache writeCacheBeingFlushed;
<i>98</i>&nbsp;
<i>99</i>&nbsp;    // Cache where we insert entries for speculative reading
<i>100</i>&nbsp;    private final ReadCache readCache;
<i>101</i>&nbsp;
<b class="nc"><i>102</i>&nbsp;    private final StampedLock writeCacheRotationLock = new StampedLock();</b>
<i>103</i>&nbsp;
<b class="nc"><i>104</i>&nbsp;    protected final ReentrantLock flushMutex = new ReentrantLock();</b>
<i>105</i>&nbsp;
<b class="nc"><i>106</i>&nbsp;    protected final AtomicBoolean hasFlushBeenTriggered = new AtomicBoolean(false);</b>
<b class="nc"><i>107</i>&nbsp;    private final AtomicBoolean isFlushOngoing = new AtomicBoolean(false);</b>
<i>108</i>&nbsp;
<b class="nc"><i>109</i>&nbsp;    private final ExecutorService executor = Executors.newSingleThreadExecutor(new DefaultThreadFactory(&quot;db-storage&quot;));</b>
<i>110</i>&nbsp;
<i>111</i>&nbsp;    // Executor used to for db index cleanup
<b class="nc"><i>112</i>&nbsp;    private final ScheduledExecutorService cleanupExecutor = Executors</b>
<b class="nc"><i>113</i>&nbsp;            .newSingleThreadScheduledExecutor(new DefaultThreadFactory(&quot;db-storage-cleanup&quot;));</b>
<i>114</i>&nbsp;
<b class="nc"><i>115</i>&nbsp;    private final CopyOnWriteArrayList&lt;LedgerDeletionListener&gt; ledgerDeletionListeners = Lists</b>
<b class="nc"><i>116</i>&nbsp;            .newCopyOnWriteArrayList();</b>
<i>117</i>&nbsp;
<i>118</i>&nbsp;    private final CheckpointSource checkpointSource;
<b class="nc"><i>119</i>&nbsp;    private Checkpoint lastCheckpoint = Checkpoint.MIN;</b>
<i>120</i>&nbsp;
<i>121</i>&nbsp;    private final long writeCacheMaxSize;
<i>122</i>&nbsp;    private final long readCacheMaxSize;
<i>123</i>&nbsp;    private final int readAheadCacheBatchSize;
<i>124</i>&nbsp;
<i>125</i>&nbsp;    private final long maxThrottleTimeNanos;
<i>126</i>&nbsp;
<i>127</i>&nbsp;    private final DbLedgerStorageStats dbLedgerStorageStats;
<i>128</i>&nbsp;
<i>129</i>&nbsp;    static final String READ_AHEAD_CACHE_BATCH_SIZE = &quot;dbStorage_readAheadCacheBatchSize&quot;;
<i>130</i>&nbsp;    private static final int DEFAULT_READ_AHEAD_CACHE_BATCH_SIZE = 100;
<i>131</i>&nbsp;
<b class="nc"><i>132</i>&nbsp;    private static final long DEFAULT_MAX_THROTTLE_TIME_MILLIS = TimeUnit.SECONDS.toMillis(10);</b>
<i>133</i>&nbsp;
<i>134</i>&nbsp;    public SingleDirectoryDbLedgerStorage(ServerConfiguration conf, LedgerManager ledgerManager,
<i>135</i>&nbsp;            LedgerDirsManager ledgerDirsManager, LedgerDirsManager indexDirsManager, StateManager stateManager,
<i>136</i>&nbsp;            CheckpointSource checkpointSource, Checkpointer checkpointer, StatsLogger statsLogger,
<i>137</i>&nbsp;            ByteBufAllocator allocator, ScheduledExecutorService gcExecutor, long writeCacheSize, long readCacheSize)
<b class="nc"><i>138</i>&nbsp;            throws IOException {</b>
<i>139</i>&nbsp;
<b class="nc"><i>140</i>&nbsp;        checkArgument(ledgerDirsManager.getAllLedgerDirs().size() == 1,</b>
<i>141</i>&nbsp;                &quot;Db implementation only allows for one storage dir&quot;);
<i>142</i>&nbsp;
<b class="nc"><i>143</i>&nbsp;        String baseDir = ledgerDirsManager.getAllLedgerDirs().get(0).toString();</b>
<b class="nc"><i>144</i>&nbsp;        log.info(&quot;Creating single directory db ledger storage on {}&quot;, baseDir);</b>
<i>145</i>&nbsp;
<b class="nc"><i>146</i>&nbsp;        this.writeCacheMaxSize = writeCacheSize;</b>
<b class="nc"><i>147</i>&nbsp;        this.writeCache = new WriteCache(allocator, writeCacheMaxSize / 2);</b>
<b class="nc"><i>148</i>&nbsp;        this.writeCacheBeingFlushed = new WriteCache(allocator, writeCacheMaxSize / 2);</b>
<i>149</i>&nbsp;
<b class="nc"><i>150</i>&nbsp;        this.checkpointSource = checkpointSource;</b>
<i>151</i>&nbsp;
<b class="nc"><i>152</i>&nbsp;        readCacheMaxSize = readCacheSize;</b>
<b class="nc"><i>153</i>&nbsp;        readAheadCacheBatchSize = conf.getInt(READ_AHEAD_CACHE_BATCH_SIZE, DEFAULT_READ_AHEAD_CACHE_BATCH_SIZE);</b>
<i>154</i>&nbsp;
<b class="nc"><i>155</i>&nbsp;        long maxThrottleTimeMillis = conf.getLong(DbLedgerStorage.MAX_THROTTLE_TIME_MILLIS,</b>
<i>156</i>&nbsp;                DEFAULT_MAX_THROTTLE_TIME_MILLIS);
<b class="nc"><i>157</i>&nbsp;        maxThrottleTimeNanos = TimeUnit.MILLISECONDS.toNanos(maxThrottleTimeMillis);</b>
<i>158</i>&nbsp;
<b class="nc"><i>159</i>&nbsp;        readCache = new ReadCache(allocator, readCacheMaxSize);</b>
<i>160</i>&nbsp;
<b class="nc"><i>161</i>&nbsp;        ledgerIndex = new LedgerMetadataIndex(conf, KeyValueStorageRocksDB.factory, baseDir, statsLogger);</b>
<b class="nc"><i>162</i>&nbsp;        entryLocationIndex = new EntryLocationIndex(conf, KeyValueStorageRocksDB.factory, baseDir, statsLogger);</b>
<i>163</i>&nbsp;
<b class="nc"><i>164</i>&nbsp;        transientLedgerInfoCache = new ConcurrentLongHashMap&lt;&gt;(16 * 1024,</b>
<b class="nc"><i>165</i>&nbsp;                Runtime.getRuntime().availableProcessors() * 2);</b>
<b class="nc"><i>166</i>&nbsp;        cleanupExecutor.scheduleAtFixedRate(this::cleanupStaleTransientLedgerInfo,</b>
<i>167</i>&nbsp;                TransientLedgerInfo.LEDGER_INFO_CACHING_TIME_MINUTES,
<i>168</i>&nbsp;                TransientLedgerInfo.LEDGER_INFO_CACHING_TIME_MINUTES, TimeUnit.MINUTES);
<i>169</i>&nbsp;
<b class="nc"><i>170</i>&nbsp;        entryLogger = new EntryLogger(conf, ledgerDirsManager, null, statsLogger, allocator);</b>
<b class="nc"><i>171</i>&nbsp;        gcThread = new GarbageCollectorThread(conf, ledgerManager, this, statsLogger);</b>
<i>172</i>&nbsp;
<b class="nc"><i>173</i>&nbsp;        dbLedgerStorageStats = new DbLedgerStorageStats(</b>
<i>174</i>&nbsp;            statsLogger,
<b class="nc"><i>175</i>&nbsp;            () -&gt; writeCache.size() + writeCacheBeingFlushed.size(),</b>
<b class="nc"><i>176</i>&nbsp;            () -&gt; writeCache.count() + writeCacheBeingFlushed.count(),</b>
<b class="nc"><i>177</i>&nbsp;            () -&gt; readCache.size(),</b>
<b class="nc"><i>178</i>&nbsp;            () -&gt; readCache.count()</b>
<i>179</i>&nbsp;        );
<b class="nc"><i>180</i>&nbsp;    }</b>
<i>181</i>&nbsp;
<i>182</i>&nbsp;    @Override
<i>183</i>&nbsp;    public void initialize(ServerConfiguration conf, LedgerManager ledgerManager, LedgerDirsManager ledgerDirsManager,
<i>184</i>&nbsp;            LedgerDirsManager indexDirsManager, StateManager stateManager, CheckpointSource checkpointSource,
<i>185</i>&nbsp;            Checkpointer checkpointer, StatsLogger statsLogger,
<i>186</i>&nbsp;            ByteBufAllocator allocator) throws IOException {
<i>187</i>&nbsp;        /// Initialized in constructor
<b class="nc"><i>188</i>&nbsp;    }</b>
<i>189</i>&nbsp;
<i>190</i>&nbsp;    /**
<i>191</i>&nbsp;     * Evict all the ledger info object that were not used recently.
<i>192</i>&nbsp;     */
<i>193</i>&nbsp;    private void cleanupStaleTransientLedgerInfo() {
<b class="nc"><i>194</i>&nbsp;        transientLedgerInfoCache.removeIf((ledgerId, ledgerInfo) -&gt; {</b>
<b class="nc"><i>195</i>&nbsp;            boolean isStale = ledgerInfo.isStale();</b>
<b class="nc"><i>196</i>&nbsp;            if (isStale) {</b>
<b class="nc"><i>197</i>&nbsp;                ledgerInfo.close();</b>
<i>198</i>&nbsp;            }
<i>199</i>&nbsp;
<b class="nc"><i>200</i>&nbsp;            return isStale;</b>
<i>201</i>&nbsp;        });
<b class="nc"><i>202</i>&nbsp;    }</b>
<i>203</i>&nbsp;
<i>204</i>&nbsp;    @Override
<i>205</i>&nbsp;    public void start() {
<b class="nc"><i>206</i>&nbsp;        gcThread.start();</b>
<b class="nc"><i>207</i>&nbsp;    }</b>
<i>208</i>&nbsp;
<i>209</i>&nbsp;    @Override
<i>210</i>&nbsp;    public void forceGC() {
<b class="nc"><i>211</i>&nbsp;        gcThread.enableForceGC();</b>
<b class="nc"><i>212</i>&nbsp;    }</b>
<i>213</i>&nbsp;
<i>214</i>&nbsp;    @Override
<i>215</i>&nbsp;    public boolean isInForceGC() {
<b class="nc"><i>216</i>&nbsp;        return gcThread.isInForceGC();</b>
<i>217</i>&nbsp;    }
<i>218</i>&nbsp;
<i>219</i>&nbsp;    @Override
<i>220</i>&nbsp;    public void shutdown() throws InterruptedException {
<i>221</i>&nbsp;        try {
<b class="nc"><i>222</i>&nbsp;            flush();</b>
<i>223</i>&nbsp;
<b class="nc"><i>224</i>&nbsp;            gcThread.shutdown();</b>
<b class="nc"><i>225</i>&nbsp;            entryLogger.shutdown();</b>
<i>226</i>&nbsp;
<b class="nc"><i>227</i>&nbsp;            cleanupExecutor.shutdown();</b>
<b class="nc"><i>228</i>&nbsp;            cleanupExecutor.awaitTermination(1, TimeUnit.SECONDS);</b>
<i>229</i>&nbsp;
<b class="nc"><i>230</i>&nbsp;            ledgerIndex.close();</b>
<b class="nc"><i>231</i>&nbsp;            entryLocationIndex.close();</b>
<i>232</i>&nbsp;
<b class="nc"><i>233</i>&nbsp;            writeCache.close();</b>
<b class="nc"><i>234</i>&nbsp;            writeCacheBeingFlushed.close();</b>
<b class="nc"><i>235</i>&nbsp;            readCache.close();</b>
<b class="nc"><i>236</i>&nbsp;            executor.shutdown();</b>
<i>237</i>&nbsp;
<b class="nc"><i>238</i>&nbsp;        } catch (IOException e) {</b>
<b class="nc"><i>239</i>&nbsp;            log.error(&quot;Error closing db storage&quot;, e);</b>
<b class="nc"><i>240</i>&nbsp;        }</b>
<b class="nc"><i>241</i>&nbsp;    }</b>
<i>242</i>&nbsp;
<i>243</i>&nbsp;    @Override
<i>244</i>&nbsp;    public boolean ledgerExists(long ledgerId) throws IOException {
<i>245</i>&nbsp;        try {
<b class="nc"><i>246</i>&nbsp;            LedgerData ledgerData = ledgerIndex.get(ledgerId);</b>
<b class="nc"><i>247</i>&nbsp;            if (log.isDebugEnabled()) {</b>
<b class="nc"><i>248</i>&nbsp;                log.debug(&quot;Ledger exists. ledger: {} : {}&quot;, ledgerId, ledgerData.getExists());</b>
<i>249</i>&nbsp;            }
<b class="nc"><i>250</i>&nbsp;            return ledgerData.getExists();</b>
<b class="nc"><i>251</i>&nbsp;        } catch (Bookie.NoLedgerException nle) {</b>
<i>252</i>&nbsp;            // ledger does not exist
<b class="nc"><i>253</i>&nbsp;            return false;</b>
<i>254</i>&nbsp;        }
<i>255</i>&nbsp;    }
<i>256</i>&nbsp;
<i>257</i>&nbsp;    @Override
<i>258</i>&nbsp;    public boolean isFenced(long ledgerId) throws IOException {
<b class="nc"><i>259</i>&nbsp;        if (log.isDebugEnabled()) {</b>
<b class="nc"><i>260</i>&nbsp;            log.debug(&quot;isFenced. ledger: {}&quot;, ledgerId);</b>
<i>261</i>&nbsp;        }
<b class="nc"><i>262</i>&nbsp;        return ledgerIndex.get(ledgerId).getFenced();</b>
<i>263</i>&nbsp;    }
<i>264</i>&nbsp;
<i>265</i>&nbsp;    @Override
<i>266</i>&nbsp;    public boolean setFenced(long ledgerId) throws IOException {
<b class="nc"><i>267</i>&nbsp;        if (log.isDebugEnabled()) {</b>
<b class="nc"><i>268</i>&nbsp;            log.debug(&quot;Set fenced. ledger: {}&quot;, ledgerId);</b>
<i>269</i>&nbsp;        }
<b class="nc"><i>270</i>&nbsp;        boolean changed = ledgerIndex.setFenced(ledgerId);</b>
<b class="nc"><i>271</i>&nbsp;        if (changed) {</b>
<i>272</i>&nbsp;            // notify all the watchers if a ledger is fenced
<b class="nc"><i>273</i>&nbsp;            TransientLedgerInfo ledgerInfo = transientLedgerInfoCache.get(ledgerId);</b>
<b class="nc"><i>274</i>&nbsp;            if (null != ledgerInfo) {</b>
<b class="nc"><i>275</i>&nbsp;                ledgerInfo.notifyWatchers(Long.MAX_VALUE);</b>
<i>276</i>&nbsp;            }
<i>277</i>&nbsp;        }
<b class="nc"><i>278</i>&nbsp;        return changed;</b>
<i>279</i>&nbsp;    }
<i>280</i>&nbsp;
<i>281</i>&nbsp;    @Override
<i>282</i>&nbsp;    public void setMasterKey(long ledgerId, byte[] masterKey) throws IOException {
<b class="nc"><i>283</i>&nbsp;        if (log.isDebugEnabled()) {</b>
<b class="nc"><i>284</i>&nbsp;            log.debug(&quot;Set master key. ledger: {}&quot;, ledgerId);</b>
<i>285</i>&nbsp;        }
<b class="nc"><i>286</i>&nbsp;        ledgerIndex.setMasterKey(ledgerId, masterKey);</b>
<b class="nc"><i>287</i>&nbsp;    }</b>
<i>288</i>&nbsp;
<i>289</i>&nbsp;    @Override
<i>290</i>&nbsp;    public byte[] readMasterKey(long ledgerId) throws IOException, BookieException {
<b class="nc"><i>291</i>&nbsp;        if (log.isDebugEnabled()) {</b>
<b class="nc"><i>292</i>&nbsp;            log.debug(&quot;Read master key. ledger: {}&quot;, ledgerId);</b>
<i>293</i>&nbsp;        }
<b class="nc"><i>294</i>&nbsp;        return ledgerIndex.get(ledgerId).getMasterKey().toByteArray();</b>
<i>295</i>&nbsp;    }
<i>296</i>&nbsp;
<i>297</i>&nbsp;    @Override
<i>298</i>&nbsp;    public long addEntry(ByteBuf entry) throws IOException, BookieException {
<b class="nc"><i>299</i>&nbsp;        long startTime = MathUtils.nowInNano();</b>
<i>300</i>&nbsp;
<b class="nc"><i>301</i>&nbsp;        long ledgerId = entry.getLong(entry.readerIndex());</b>
<b class="nc"><i>302</i>&nbsp;        long entryId = entry.getLong(entry.readerIndex() + 8);</b>
<b class="nc"><i>303</i>&nbsp;        long lac = entry.getLong(entry.readerIndex() + 16);</b>
<i>304</i>&nbsp;
<b class="nc"><i>305</i>&nbsp;        if (log.isDebugEnabled()) {</b>
<b class="nc"><i>306</i>&nbsp;            log.debug(&quot;Add entry. {}@{}, lac = {}&quot;, ledgerId, entryId, lac);</b>
<i>307</i>&nbsp;        }
<i>308</i>&nbsp;
<i>309</i>&nbsp;        // First we try to do an optimistic locking to get access to the current write cache.
<i>310</i>&nbsp;        // This is based on the fact that the write cache is only being rotated (swapped) every 1 minute. During the
<i>311</i>&nbsp;        // rest of the time, we can have multiple thread using the optimistic lock here without interfering.
<b class="nc"><i>312</i>&nbsp;        long stamp = writeCacheRotationLock.tryOptimisticRead();</b>
<b class="nc"><i>313</i>&nbsp;        boolean inserted = false;</b>
<i>314</i>&nbsp;
<b class="nc"><i>315</i>&nbsp;        inserted = writeCache.put(ledgerId, entryId, entry);</b>
<b class="nc"><i>316</i>&nbsp;        if (!writeCacheRotationLock.validate(stamp)) {</b>
<i>317</i>&nbsp;            // The write cache was rotated while we were inserting. We need to acquire the proper read lock and repeat
<i>318</i>&nbsp;            // the operation because we might have inserted in a write cache that was already being flushed and cleared,
<i>319</i>&nbsp;            // without being sure about this last entry being flushed or not.
<b class="nc"><i>320</i>&nbsp;            stamp = writeCacheRotationLock.readLock();</b>
<i>321</i>&nbsp;            try {
<b class="nc"><i>322</i>&nbsp;                inserted = writeCache.put(ledgerId, entryId, entry);</b>
<i>323</i>&nbsp;            } finally {
<b class="nc"><i>324</i>&nbsp;                writeCacheRotationLock.unlockRead(stamp);</b>
<i>325</i>&nbsp;            }
<i>326</i>&nbsp;        }
<i>327</i>&nbsp;
<b class="nc"><i>328</i>&nbsp;        if (!inserted) {</b>
<b class="nc"><i>329</i>&nbsp;            triggerFlushAndAddEntry(ledgerId, entryId, entry);</b>
<i>330</i>&nbsp;        }
<i>331</i>&nbsp;
<i>332</i>&nbsp;        // after successfully insert the entry, update LAC and notify the watchers
<b class="nc"><i>333</i>&nbsp;        updateCachedLacIfNeeded(ledgerId, lac);</b>
<i>334</i>&nbsp;
<b class="nc"><i>335</i>&nbsp;        recordSuccessfulEvent(dbLedgerStorageStats.getAddEntryStats(), startTime);</b>
<b class="nc"><i>336</i>&nbsp;        return entryId;</b>
<i>337</i>&nbsp;    }
<i>338</i>&nbsp;
<i>339</i>&nbsp;    private void triggerFlushAndAddEntry(long ledgerId, long entryId, ByteBuf entry)
<i>340</i>&nbsp;            throws IOException, BookieException {
<i>341</i>&nbsp;        // Write cache is full, we need to trigger a flush so that it gets rotated
<i>342</i>&nbsp;        // If the flush has already been triggered or flush has already switched the
<i>343</i>&nbsp;        // cache, we don&#39;t need to trigger another flush
<b class="nc"><i>344</i>&nbsp;        if (!isFlushOngoing.get() &amp;&amp; hasFlushBeenTriggered.compareAndSet(false, true)) {</b>
<i>345</i>&nbsp;            // Trigger an early flush in background
<b class="nc"><i>346</i>&nbsp;            log.info(&quot;Write cache is full, triggering flush&quot;);</b>
<b class="nc"><i>347</i>&nbsp;            executor.execute(() -&gt; {</b>
<i>348</i>&nbsp;                try {
<b class="nc"><i>349</i>&nbsp;                    flush();</b>
<b class="nc"><i>350</i>&nbsp;                } catch (IOException e) {</b>
<b class="nc"><i>351</i>&nbsp;                    log.error(&quot;Error during flush&quot;, e);</b>
<b class="nc"><i>352</i>&nbsp;                }</b>
<b class="nc"><i>353</i>&nbsp;            });</b>
<i>354</i>&nbsp;        }
<i>355</i>&nbsp;
<b class="nc"><i>356</i>&nbsp;        dbLedgerStorageStats.getThrottledWriteRequests().inc();</b>
<b class="nc"><i>357</i>&nbsp;        long absoluteTimeoutNanos = System.nanoTime() + maxThrottleTimeNanos;</b>
<i>358</i>&nbsp;
<b class="nc"><i>359</i>&nbsp;        while (System.nanoTime() &lt; absoluteTimeoutNanos) {</b>
<b class="nc"><i>360</i>&nbsp;            long stamp = writeCacheRotationLock.readLock();</b>
<i>361</i>&nbsp;            try {
<b class="nc"><i>362</i>&nbsp;                if (writeCache.put(ledgerId, entryId, entry)) {</b>
<i>363</i>&nbsp;                    // We succeeded in putting the entry in write cache in the
<b class="nc"><i>364</i>&nbsp;                    return;</b>
<i>365</i>&nbsp;                }
<i>366</i>&nbsp;            } finally {
<b class="nc"><i>367</i>&nbsp;                writeCacheRotationLock.unlockRead(stamp);</b>
<i>368</i>&nbsp;            }
<i>369</i>&nbsp;
<i>370</i>&nbsp;            // Wait some time and try again
<i>371</i>&nbsp;            try {
<b class="nc"><i>372</i>&nbsp;                Thread.sleep(1);</b>
<b class="nc"><i>373</i>&nbsp;            } catch (InterruptedException e) {</b>
<b class="nc"><i>374</i>&nbsp;                Thread.currentThread().interrupt();</b>
<b class="nc"><i>375</i>&nbsp;                throw new IOException(&quot;Interrupted when adding entry &quot; + ledgerId + &quot;@&quot; + entryId);</b>
<b class="nc"><i>376</i>&nbsp;            }</b>
<b class="nc"><i>377</i>&nbsp;        }</b>
<i>378</i>&nbsp;
<i>379</i>&nbsp;        // Timeout expired and we weren&#39;t able to insert in write cache
<b class="nc"><i>380</i>&nbsp;        dbLedgerStorageStats.getRejectedWriteRequests().inc();</b>
<b class="nc"><i>381</i>&nbsp;        throw new OperationRejectedException();</b>
<i>382</i>&nbsp;    }
<i>383</i>&nbsp;
<i>384</i>&nbsp;    @Override
<i>385</i>&nbsp;    public ByteBuf getEntry(long ledgerId, long entryId) throws IOException {
<b class="nc"><i>386</i>&nbsp;        long startTime = MathUtils.nowInNano();</b>
<b class="nc"><i>387</i>&nbsp;        if (log.isDebugEnabled()) {</b>
<b class="nc"><i>388</i>&nbsp;            log.debug(&quot;Get Entry: {}@{}&quot;, ledgerId, entryId);</b>
<i>389</i>&nbsp;        }
<i>390</i>&nbsp;
<b class="nc"><i>391</i>&nbsp;        if (entryId == BookieProtocol.LAST_ADD_CONFIRMED) {</b>
<b class="nc"><i>392</i>&nbsp;            return getLastEntry(ledgerId);</b>
<i>393</i>&nbsp;        }
<i>394</i>&nbsp;
<i>395</i>&nbsp;        // We need to try to read from both write caches, since recent entries could be found in either of the two. The
<i>396</i>&nbsp;        // write caches are already thread safe on their own, here we just need to make sure we get references to both
<i>397</i>&nbsp;        // of them. Using an optimistic lock since the read lock is always free, unless we&#39;re swapping the caches.
<b class="nc"><i>398</i>&nbsp;        long stamp = writeCacheRotationLock.tryOptimisticRead();</b>
<b class="nc"><i>399</i>&nbsp;        WriteCache localWriteCache = writeCache;</b>
<b class="nc"><i>400</i>&nbsp;        WriteCache localWriteCacheBeingFlushed = writeCacheBeingFlushed;</b>
<b class="nc"><i>401</i>&nbsp;        if (!writeCacheRotationLock.validate(stamp)) {</b>
<i>402</i>&nbsp;            // Fallback to regular read lock approach
<b class="nc"><i>403</i>&nbsp;            stamp = writeCacheRotationLock.readLock();</b>
<i>404</i>&nbsp;            try {
<b class="nc"><i>405</i>&nbsp;                localWriteCache = writeCache;</b>
<b class="nc"><i>406</i>&nbsp;                localWriteCacheBeingFlushed = writeCacheBeingFlushed;</b>
<i>407</i>&nbsp;            } finally {
<b class="nc"><i>408</i>&nbsp;                writeCacheRotationLock.unlockRead(stamp);</b>
<i>409</i>&nbsp;            }
<i>410</i>&nbsp;        }
<i>411</i>&nbsp;
<i>412</i>&nbsp;        // First try to read from the write cache of recent entries
<b class="nc"><i>413</i>&nbsp;        ByteBuf entry = localWriteCache.get(ledgerId, entryId);</b>
<b class="nc"><i>414</i>&nbsp;        if (entry != null) {</b>
<b class="nc"><i>415</i>&nbsp;            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</b>
<b class="nc"><i>416</i>&nbsp;            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</b>
<b class="nc"><i>417</i>&nbsp;            return entry;</b>
<i>418</i>&nbsp;        }
<i>419</i>&nbsp;
<i>420</i>&nbsp;        // If there&#39;s a flush going on, the entry might be in the flush buffer
<b class="nc"><i>421</i>&nbsp;        entry = localWriteCacheBeingFlushed.get(ledgerId, entryId);</b>
<b class="nc"><i>422</i>&nbsp;        if (entry != null) {</b>
<b class="nc"><i>423</i>&nbsp;            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</b>
<b class="nc"><i>424</i>&nbsp;            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</b>
<b class="nc"><i>425</i>&nbsp;            return entry;</b>
<i>426</i>&nbsp;        }
<i>427</i>&nbsp;
<i>428</i>&nbsp;        // Try reading from read-ahead cache
<b class="nc"><i>429</i>&nbsp;        entry = readCache.get(ledgerId, entryId);</b>
<b class="nc"><i>430</i>&nbsp;        if (entry != null) {</b>
<b class="nc"><i>431</i>&nbsp;            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</b>
<b class="nc"><i>432</i>&nbsp;            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</b>
<b class="nc"><i>433</i>&nbsp;            return entry;</b>
<i>434</i>&nbsp;        }
<i>435</i>&nbsp;
<i>436</i>&nbsp;        // Read from main storage
<i>437</i>&nbsp;        long entryLocation;
<i>438</i>&nbsp;        try {
<b class="nc"><i>439</i>&nbsp;            entryLocation = entryLocationIndex.getLocation(ledgerId, entryId);</b>
<b class="nc"><i>440</i>&nbsp;            if (entryLocation == 0) {</b>
<b class="nc"><i>441</i>&nbsp;                throw new NoEntryException(ledgerId, entryId);</b>
<i>442</i>&nbsp;            }
<b class="nc"><i>443</i>&nbsp;            entry = entryLogger.readEntry(ledgerId, entryId, entryLocation);</b>
<b class="nc"><i>444</i>&nbsp;        } catch (NoEntryException e) {</b>
<b class="nc"><i>445</i>&nbsp;            recordFailedEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</b>
<b class="nc"><i>446</i>&nbsp;            throw e;</b>
<b class="nc"><i>447</i>&nbsp;        }</b>
<i>448</i>&nbsp;
<b class="nc"><i>449</i>&nbsp;        readCache.put(ledgerId, entryId, entry);</b>
<i>450</i>&nbsp;
<i>451</i>&nbsp;        // Try to read more entries
<b class="nc"><i>452</i>&nbsp;        long nextEntryLocation = entryLocation + 4 /* size header */ + entry.readableBytes();</b>
<b class="nc"><i>453</i>&nbsp;        fillReadAheadCache(ledgerId, entryId + 1, nextEntryLocation);</b>
<i>454</i>&nbsp;
<b class="nc"><i>455</i>&nbsp;        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);</b>
<b class="nc"><i>456</i>&nbsp;        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</b>
<b class="nc"><i>457</i>&nbsp;        return entry;</b>
<i>458</i>&nbsp;    }
<i>459</i>&nbsp;
<i>460</i>&nbsp;    private void fillReadAheadCache(long orginalLedgerId, long firstEntryId, long firstEntryLocation) {
<i>461</i>&nbsp;        try {
<b class="nc"><i>462</i>&nbsp;            long firstEntryLogId = (firstEntryLocation &gt;&gt; 32);</b>
<b class="nc"><i>463</i>&nbsp;            long currentEntryLogId = firstEntryLogId;</b>
<b class="nc"><i>464</i>&nbsp;            long currentEntryLocation = firstEntryLocation;</b>
<b class="nc"><i>465</i>&nbsp;            int count = 0;</b>
<b class="nc"><i>466</i>&nbsp;            long size = 0;</b>
<i>467</i>&nbsp;
<b class="nc"><i>468</i>&nbsp;            while (count &lt; readAheadCacheBatchSize &amp;&amp; currentEntryLogId == firstEntryLogId) {</b>
<b class="nc"><i>469</i>&nbsp;                ByteBuf entry = entryLogger.internalReadEntry(orginalLedgerId, firstEntryId, currentEntryLocation,</b>
<i>470</i>&nbsp;                        false /* validateEntry */);
<i>471</i>&nbsp;
<i>472</i>&nbsp;                try {
<b class="nc"><i>473</i>&nbsp;                    long currentEntryLedgerId = entry.getLong(0);</b>
<b class="nc"><i>474</i>&nbsp;                    long currentEntryId = entry.getLong(8);</b>
<i>475</i>&nbsp;
<b class="nc"><i>476</i>&nbsp;                    if (currentEntryLedgerId != orginalLedgerId) {</b>
<i>477</i>&nbsp;                        // Found an entry belonging to a different ledger, stopping read-ahead
<i>478</i>&nbsp;                        break;
<i>479</i>&nbsp;                    }
<i>480</i>&nbsp;
<i>481</i>&nbsp;                    // Insert entry in read cache
<b class="nc"><i>482</i>&nbsp;                    readCache.put(orginalLedgerId, currentEntryId, entry);</b>
<i>483</i>&nbsp;
<b class="nc"><i>484</i>&nbsp;                    count++;</b>
<b class="nc"><i>485</i>&nbsp;                    firstEntryId++;</b>
<b class="nc"><i>486</i>&nbsp;                    size += entry.readableBytes();</b>
<i>487</i>&nbsp;
<b class="nc"><i>488</i>&nbsp;                    currentEntryLocation += 4 + entry.readableBytes();</b>
<b class="nc"><i>489</i>&nbsp;                    currentEntryLogId = currentEntryLocation &gt;&gt; 32;</b>
<i>490</i>&nbsp;                } finally {
<b class="nc"><i>491</i>&nbsp;                    entry.release();</b>
<i>492</i>&nbsp;                }
<b class="nc"><i>493</i>&nbsp;            }</b>
<i>494</i>&nbsp;
<b class="nc"><i>495</i>&nbsp;            dbLedgerStorageStats.getReadAheadBatchCountStats().registerSuccessfulValue(count);</b>
<b class="nc"><i>496</i>&nbsp;            dbLedgerStorageStats.getReadAheadBatchSizeStats().registerSuccessfulValue(size);</b>
<b class="nc"><i>497</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>498</i>&nbsp;            if (log.isDebugEnabled()) {</b>
<b class="nc"><i>499</i>&nbsp;                log.debug(&quot;Exception during read ahead for ledger: {}: e&quot;, orginalLedgerId, e);</b>
<i>500</i>&nbsp;            }
<b class="nc"><i>501</i>&nbsp;        }</b>
<b class="nc"><i>502</i>&nbsp;    }</b>
<i>503</i>&nbsp;
<i>504</i>&nbsp;    public ByteBuf getLastEntry(long ledgerId) throws IOException {
<b class="nc"><i>505</i>&nbsp;        long startTime = MathUtils.nowInNano();</b>
<i>506</i>&nbsp;
<b class="nc"><i>507</i>&nbsp;        long stamp = writeCacheRotationLock.readLock();</b>
<i>508</i>&nbsp;        try {
<i>509</i>&nbsp;            // First try to read from the write cache of recent entries
<b class="nc"><i>510</i>&nbsp;            ByteBuf entry = writeCache.getLastEntry(ledgerId);</b>
<b class="nc"><i>511</i>&nbsp;            if (entry != null) {</b>
<b class="nc"><i>512</i>&nbsp;                if (log.isDebugEnabled()) {</b>
<b class="nc"><i>513</i>&nbsp;                    long foundLedgerId = entry.readLong(); // ledgedId</b>
<b class="nc"><i>514</i>&nbsp;                    long entryId = entry.readLong();</b>
<b class="nc"><i>515</i>&nbsp;                    entry.resetReaderIndex();</b>
<b class="nc"><i>516</i>&nbsp;                    if (log.isDebugEnabled()) {</b>
<b class="nc"><i>517</i>&nbsp;                        log.debug(&quot;Found last entry for ledger {} in write cache: {}@{}&quot;, ledgerId, foundLedgerId,</b>
<b class="nc"><i>518</i>&nbsp;                                entryId);</b>
<i>519</i>&nbsp;                    }
<i>520</i>&nbsp;                }
<i>521</i>&nbsp;
<b class="nc"><i>522</i>&nbsp;                recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</b>
<b class="nc"><i>523</i>&nbsp;                recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</b>
<b class="nc"><i>524</i>&nbsp;                return entry;</b>
<i>525</i>&nbsp;            }
<i>526</i>&nbsp;
<i>527</i>&nbsp;            // If there&#39;s a flush going on, the entry might be in the flush buffer
<b class="nc"><i>528</i>&nbsp;            entry = writeCacheBeingFlushed.getLastEntry(ledgerId);</b>
<b class="nc"><i>529</i>&nbsp;            if (entry != null) {</b>
<b class="nc"><i>530</i>&nbsp;                if (log.isDebugEnabled()) {</b>
<b class="nc"><i>531</i>&nbsp;                    entry.readLong(); // ledgedId</b>
<b class="nc"><i>532</i>&nbsp;                    long entryId = entry.readLong();</b>
<b class="nc"><i>533</i>&nbsp;                    entry.resetReaderIndex();</b>
<b class="nc"><i>534</i>&nbsp;                    if (log.isDebugEnabled()) {</b>
<b class="nc"><i>535</i>&nbsp;                        log.debug(&quot;Found last entry for ledger {} in write cache being flushed: {}&quot;, ledgerId, entryId);</b>
<i>536</i>&nbsp;                    }
<i>537</i>&nbsp;                }
<i>538</i>&nbsp;
<b class="nc"><i>539</i>&nbsp;                recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</b>
<b class="nc"><i>540</i>&nbsp;                recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</b>
<b class="nc"><i>541</i>&nbsp;                return entry;</b>
<i>542</i>&nbsp;            }
<i>543</i>&nbsp;        } finally {
<b class="nc"><i>544</i>&nbsp;            writeCacheRotationLock.unlockRead(stamp);</b>
<i>545</i>&nbsp;        }
<i>546</i>&nbsp;
<i>547</i>&nbsp;        // Search the last entry in storage
<b class="nc"><i>548</i>&nbsp;        long lastEntryId = entryLocationIndex.getLastEntryInLedger(ledgerId);</b>
<b class="nc"><i>549</i>&nbsp;        if (log.isDebugEnabled()) {</b>
<b class="nc"><i>550</i>&nbsp;            log.debug(&quot;Found last entry for ledger {} in db: {}&quot;, ledgerId, lastEntryId);</b>
<i>551</i>&nbsp;        }
<i>552</i>&nbsp;
<b class="nc"><i>553</i>&nbsp;        long entryLocation = entryLocationIndex.getLocation(ledgerId, lastEntryId);</b>
<b class="nc"><i>554</i>&nbsp;        ByteBuf content = entryLogger.readEntry(ledgerId, lastEntryId, entryLocation);</b>
<i>555</i>&nbsp;
<b class="nc"><i>556</i>&nbsp;        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);</b>
<b class="nc"><i>557</i>&nbsp;        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</b>
<b class="nc"><i>558</i>&nbsp;        return content;</b>
<i>559</i>&nbsp;    }
<i>560</i>&nbsp;
<i>561</i>&nbsp;    @VisibleForTesting
<i>562</i>&nbsp;    boolean isFlushRequired() {
<b class="nc"><i>563</i>&nbsp;        long stamp = writeCacheRotationLock.readLock();</b>
<i>564</i>&nbsp;        try {
<b class="nc"><i>565</i>&nbsp;            return !writeCache.isEmpty();</b>
<i>566</i>&nbsp;        } finally {
<b class="nc"><i>567</i>&nbsp;            writeCacheRotationLock.unlockRead(stamp);</b>
<i>568</i>&nbsp;        }
<i>569</i>&nbsp;    }
<i>570</i>&nbsp;
<i>571</i>&nbsp;    @Override
<i>572</i>&nbsp;    public void checkpoint(Checkpoint checkpoint) throws IOException {
<b class="nc"><i>573</i>&nbsp;        Checkpoint thisCheckpoint = checkpointSource.newCheckpoint();</b>
<b class="nc"><i>574</i>&nbsp;        if (lastCheckpoint.compareTo(checkpoint) &gt; 0) {</b>
<b class="nc"><i>575</i>&nbsp;            return;</b>
<i>576</i>&nbsp;        }
<i>577</i>&nbsp;
<b class="nc"><i>578</i>&nbsp;        long startTime = MathUtils.nowInNano();</b>
<i>579</i>&nbsp;
<i>580</i>&nbsp;        // Only a single flush operation can happen at a time
<b class="nc"><i>581</i>&nbsp;        flushMutex.lock();</b>
<i>582</i>&nbsp;
<i>583</i>&nbsp;        try {
<i>584</i>&nbsp;            // Swap the write cache so that writes can continue to happen while the flush is
<i>585</i>&nbsp;            // ongoing
<b class="nc"><i>586</i>&nbsp;            swapWriteCache();</b>
<i>587</i>&nbsp;
<b class="nc"><i>588</i>&nbsp;            long sizeToFlush = writeCacheBeingFlushed.size();</b>
<b class="nc"><i>589</i>&nbsp;            if (log.isDebugEnabled()) {</b>
<b class="nc"><i>590</i>&nbsp;                log.debug(&quot;Flushing entries. count: {} -- size {} Mb&quot;, writeCacheBeingFlushed.count(),</b>
<b class="nc"><i>591</i>&nbsp;                        sizeToFlush / 1024.0 / 1024);</b>
<i>592</i>&nbsp;            }
<i>593</i>&nbsp;
<i>594</i>&nbsp;            // Write all the pending entries into the entry logger and collect the offset
<i>595</i>&nbsp;            // position for each entry
<i>596</i>&nbsp;
<b class="nc"><i>597</i>&nbsp;            Batch batch = entryLocationIndex.newBatch();</b>
<b class="nc"><i>598</i>&nbsp;            writeCacheBeingFlushed.forEach((ledgerId, entryId, entry) -&gt; {</b>
<i>599</i>&nbsp;                try {
<b class="nc"><i>600</i>&nbsp;                    long location = entryLogger.addEntry(ledgerId, entry, true);</b>
<b class="nc"><i>601</i>&nbsp;                    entryLocationIndex.addLocation(batch, ledgerId, entryId, location);</b>
<b class="nc"><i>602</i>&nbsp;                } catch (IOException e) {</b>
<b class="nc"><i>603</i>&nbsp;                    throw new RuntimeException(e);</b>
<b class="nc"><i>604</i>&nbsp;                }</b>
<b class="nc"><i>605</i>&nbsp;            });</b>
<i>606</i>&nbsp;
<b class="nc"><i>607</i>&nbsp;            entryLogger.flush();</b>
<i>608</i>&nbsp;
<b class="nc"><i>609</i>&nbsp;            long batchFlushStarTime = System.nanoTime();</b>
<b class="nc"><i>610</i>&nbsp;            batch.flush();</b>
<b class="nc"><i>611</i>&nbsp;            batch.close();</b>
<b class="nc"><i>612</i>&nbsp;            if (log.isDebugEnabled()) {</b>
<b class="nc"><i>613</i>&nbsp;                log.debug(&quot;DB batch flushed time : {} s&quot;,</b>
<b class="nc"><i>614</i>&nbsp;                        MathUtils.elapsedNanos(batchFlushStarTime) / (double) TimeUnit.SECONDS.toNanos(1));</b>
<i>615</i>&nbsp;            }
<i>616</i>&nbsp;
<b class="nc"><i>617</i>&nbsp;            ledgerIndex.flush();</b>
<i>618</i>&nbsp;
<b class="nc"><i>619</i>&nbsp;            cleanupExecutor.execute(() -&gt; {</b>
<i>620</i>&nbsp;                // There can only be one single cleanup task running because the cleanupExecutor
<i>621</i>&nbsp;                // is single-threaded
<i>622</i>&nbsp;                try {
<b class="nc"><i>623</i>&nbsp;                    if (log.isDebugEnabled()) {</b>
<b class="nc"><i>624</i>&nbsp;                        log.debug(&quot;Removing deleted ledgers from db indexes&quot;);</b>
<i>625</i>&nbsp;                    }
<i>626</i>&nbsp;
<b class="nc"><i>627</i>&nbsp;                    entryLocationIndex.removeOffsetFromDeletedLedgers();</b>
<b class="nc"><i>628</i>&nbsp;                    ledgerIndex.removeDeletedLedgers();</b>
<b class="nc"><i>629</i>&nbsp;                } catch (Throwable t) {</b>
<b class="nc"><i>630</i>&nbsp;                    log.warn(&quot;Failed to cleanup db indexes&quot;, t);</b>
<b class="nc"><i>631</i>&nbsp;                }</b>
<b class="nc"><i>632</i>&nbsp;            });</b>
<i>633</i>&nbsp;
<b class="nc"><i>634</i>&nbsp;            lastCheckpoint = thisCheckpoint;</b>
<i>635</i>&nbsp;
<i>636</i>&nbsp;            // Discard all the entry from the write cache, since they&#39;re now persisted
<b class="nc"><i>637</i>&nbsp;            writeCacheBeingFlushed.clear();</b>
<i>638</i>&nbsp;
<b class="nc"><i>639</i>&nbsp;            double flushTimeSeconds = MathUtils.elapsedNanos(startTime) / (double) TimeUnit.SECONDS.toNanos(1);</b>
<b class="nc"><i>640</i>&nbsp;            double flushThroughput = sizeToFlush / 1024.0 / 1024.0 / flushTimeSeconds;</b>
<i>641</i>&nbsp;
<b class="nc"><i>642</i>&nbsp;            if (log.isDebugEnabled()) {</b>
<b class="nc"><i>643</i>&nbsp;                log.debug(&quot;Flushing done time {} s -- Written {} MB/s&quot;, flushTimeSeconds, flushThroughput);</b>
<i>644</i>&nbsp;            }
<i>645</i>&nbsp;
<b class="nc"><i>646</i>&nbsp;            recordSuccessfulEvent(dbLedgerStorageStats.getFlushStats(), startTime);</b>
<b class="nc"><i>647</i>&nbsp;            dbLedgerStorageStats.getFlushSizeStats().registerSuccessfulValue(sizeToFlush);</b>
<b class="nc"><i>648</i>&nbsp;        } catch (IOException e) {</b>
<i>649</i>&nbsp;            // Leave IOExecption as it is
<b class="nc"><i>650</i>&nbsp;            throw e;</b>
<b class="nc"><i>651</i>&nbsp;        } catch (RuntimeException e) {</b>
<i>652</i>&nbsp;            // Wrap unchecked exceptions
<b class="nc"><i>653</i>&nbsp;            throw new IOException(e);</b>
<i>654</i>&nbsp;        } finally {
<i>655</i>&nbsp;            try {
<b class="nc"><i>656</i>&nbsp;                isFlushOngoing.set(false);</b>
<i>657</i>&nbsp;            } finally {
<b class="nc"><i>658</i>&nbsp;                flushMutex.unlock();</b>
<i>659</i>&nbsp;            }
<i>660</i>&nbsp;        }
<b class="nc"><i>661</i>&nbsp;    }</b>
<i>662</i>&nbsp;
<i>663</i>&nbsp;    /**
<i>664</i>&nbsp;     * Swap the current write cache with the replacement cache.
<i>665</i>&nbsp;     */
<i>666</i>&nbsp;    private void swapWriteCache() {
<b class="nc"><i>667</i>&nbsp;        long stamp = writeCacheRotationLock.writeLock();</b>
<i>668</i>&nbsp;        try {
<i>669</i>&nbsp;            // First, swap the current write-cache map with an empty one so that writes will
<i>670</i>&nbsp;            // go on unaffected. Only a single flush is happening at the same time
<b class="nc"><i>671</i>&nbsp;            WriteCache tmp = writeCacheBeingFlushed;</b>
<b class="nc"><i>672</i>&nbsp;            writeCacheBeingFlushed = writeCache;</b>
<b class="nc"><i>673</i>&nbsp;            writeCache = tmp;</b>
<i>674</i>&nbsp;
<i>675</i>&nbsp;            // since the cache is switched, we can allow flush to be triggered
<b class="nc"><i>676</i>&nbsp;            hasFlushBeenTriggered.set(false);</b>
<i>677</i>&nbsp;        } finally {
<i>678</i>&nbsp;            try {
<b class="nc"><i>679</i>&nbsp;                isFlushOngoing.set(true);</b>
<i>680</i>&nbsp;            } finally {
<b class="nc"><i>681</i>&nbsp;                writeCacheRotationLock.unlockWrite(stamp);</b>
<i>682</i>&nbsp;            }
<i>683</i>&nbsp;        }
<b class="nc"><i>684</i>&nbsp;    }</b>
<i>685</i>&nbsp;
<i>686</i>&nbsp;    @Override
<i>687</i>&nbsp;    public void flush() throws IOException {
<b class="nc"><i>688</i>&nbsp;        Checkpoint cp = checkpointSource.newCheckpoint();</b>
<b class="nc"><i>689</i>&nbsp;        checkpoint(cp);</b>
<b class="nc"><i>690</i>&nbsp;        checkpointSource.checkpointComplete(cp, true);</b>
<b class="nc"><i>691</i>&nbsp;    }</b>
<i>692</i>&nbsp;
<i>693</i>&nbsp;    @Override
<i>694</i>&nbsp;    public void deleteLedger(long ledgerId) throws IOException {
<b class="nc"><i>695</i>&nbsp;        if (log.isDebugEnabled()) {</b>
<b class="nc"><i>696</i>&nbsp;            log.debug(&quot;Deleting ledger {}&quot;, ledgerId);</b>
<i>697</i>&nbsp;        }
<i>698</i>&nbsp;
<i>699</i>&nbsp;        // Delete entries from this ledger that are still in the write cache
<b class="nc"><i>700</i>&nbsp;        long stamp = writeCacheRotationLock.readLock();</b>
<i>701</i>&nbsp;        try {
<b class="nc"><i>702</i>&nbsp;            writeCache.deleteLedger(ledgerId);</b>
<i>703</i>&nbsp;        } finally {
<b class="nc"><i>704</i>&nbsp;            writeCacheRotationLock.unlockRead(stamp);</b>
<i>705</i>&nbsp;        }
<i>706</i>&nbsp;
<b class="nc"><i>707</i>&nbsp;        entryLocationIndex.delete(ledgerId);</b>
<b class="nc"><i>708</i>&nbsp;        ledgerIndex.delete(ledgerId);</b>
<i>709</i>&nbsp;
<b class="nc"><i>710</i>&nbsp;        for (int i = 0, size = ledgerDeletionListeners.size(); i &lt; size; i++) {</b>
<b class="nc"><i>711</i>&nbsp;            LedgerDeletionListener listener = ledgerDeletionListeners.get(i);</b>
<b class="nc"><i>712</i>&nbsp;            listener.ledgerDeleted(ledgerId);</b>
<i>713</i>&nbsp;        }
<i>714</i>&nbsp;
<b class="nc"><i>715</i>&nbsp;        TransientLedgerInfo tli = transientLedgerInfoCache.remove(ledgerId);</b>
<b class="nc"><i>716</i>&nbsp;        if (tli != null) {</b>
<b class="nc"><i>717</i>&nbsp;            tli.close();</b>
<i>718</i>&nbsp;        }
<b class="nc"><i>719</i>&nbsp;    }</b>
<i>720</i>&nbsp;
<i>721</i>&nbsp;    @Override
<i>722</i>&nbsp;    public Iterable&lt;Long&gt; getActiveLedgersInRange(long firstLedgerId, long lastLedgerId) throws IOException {
<b class="nc"><i>723</i>&nbsp;        return ledgerIndex.getActiveLedgersInRange(firstLedgerId, lastLedgerId);</b>
<i>724</i>&nbsp;    }
<i>725</i>&nbsp;
<i>726</i>&nbsp;    @Override
<i>727</i>&nbsp;    public void updateEntriesLocations(Iterable&lt;EntryLocation&gt; locations) throws IOException {
<i>728</i>&nbsp;        // Trigger a flush to have all the entries being compacted in the db storage
<b class="nc"><i>729</i>&nbsp;        flush();</b>
<i>730</i>&nbsp;
<b class="nc"><i>731</i>&nbsp;        entryLocationIndex.updateLocations(locations);</b>
<b class="nc"><i>732</i>&nbsp;    }</b>
<i>733</i>&nbsp;
<i>734</i>&nbsp;    @Override
<i>735</i>&nbsp;    public EntryLogger getEntryLogger() {
<b class="nc"><i>736</i>&nbsp;        return entryLogger;</b>
<i>737</i>&nbsp;    }
<i>738</i>&nbsp;
<i>739</i>&nbsp;    @Override
<i>740</i>&nbsp;    public long getLastAddConfirmed(long ledgerId) throws IOException {
<b class="nc"><i>741</i>&nbsp;        TransientLedgerInfo ledgerInfo = transientLedgerInfoCache.get(ledgerId);</b>
<b class="nc"><i>742</i>&nbsp;        long lac = null != ledgerInfo ? ledgerInfo.getLastAddConfirmed() : TransientLedgerInfo.NOT_ASSIGNED_LAC;</b>
<b class="nc"><i>743</i>&nbsp;        if (lac == TransientLedgerInfo.NOT_ASSIGNED_LAC) {</b>
<b class="nc"><i>744</i>&nbsp;            ByteBuf bb = getEntry(ledgerId, BookieProtocol.LAST_ADD_CONFIRMED);</b>
<i>745</i>&nbsp;            try {
<b class="nc"><i>746</i>&nbsp;                bb.skipBytes(2 * Long.BYTES); // skip ledger id and entry id</b>
<b class="nc"><i>747</i>&nbsp;                lac = bb.readLong();</b>
<b class="nc"><i>748</i>&nbsp;                lac = getOrAddLedgerInfo(ledgerId).setLastAddConfirmed(lac);</b>
<i>749</i>&nbsp;            } finally {
<b class="nc"><i>750</i>&nbsp;                bb.release();</b>
<i>751</i>&nbsp;            }
<i>752</i>&nbsp;        }
<b class="nc"><i>753</i>&nbsp;        return lac;</b>
<i>754</i>&nbsp;    }
<i>755</i>&nbsp;
<i>756</i>&nbsp;    @Override
<i>757</i>&nbsp;    public boolean waitForLastAddConfirmedUpdate(long ledgerId, long previousLAC,
<i>758</i>&nbsp;            Watcher&lt;LastAddConfirmedUpdateNotification&gt; watcher) throws IOException {
<b class="nc"><i>759</i>&nbsp;        return getOrAddLedgerInfo(ledgerId).waitForLastAddConfirmedUpdate(previousLAC, watcher);</b>
<i>760</i>&nbsp;    }
<i>761</i>&nbsp;
<i>762</i>&nbsp;    @Override
<i>763</i>&nbsp;    public void cancelWaitForLastAddConfirmedUpdate(long ledgerId,
<i>764</i>&nbsp;                                                    Watcher&lt;LastAddConfirmedUpdateNotification&gt; watcher)
<i>765</i>&nbsp;            throws IOException {
<b class="nc"><i>766</i>&nbsp;        getOrAddLedgerInfo(ledgerId).cancelWaitForLastAddConfirmedUpdate(watcher);</b>
<b class="nc"><i>767</i>&nbsp;    }</b>
<i>768</i>&nbsp;
<i>769</i>&nbsp;    @Override
<i>770</i>&nbsp;    public void setExplicitlac(long ledgerId, ByteBuf lac) throws IOException {
<b class="nc"><i>771</i>&nbsp;        getOrAddLedgerInfo(ledgerId).setExplicitLac(lac);</b>
<b class="nc"><i>772</i>&nbsp;    }</b>
<i>773</i>&nbsp;
<i>774</i>&nbsp;    @Override
<i>775</i>&nbsp;    public ByteBuf getExplicitLac(long ledgerId) {
<b class="nc"><i>776</i>&nbsp;        TransientLedgerInfo ledgerInfo = transientLedgerInfoCache.get(ledgerId);</b>
<b class="nc"><i>777</i>&nbsp;        if (null == ledgerInfo) {</b>
<b class="nc"><i>778</i>&nbsp;            return null;</b>
<i>779</i>&nbsp;        } else {
<b class="nc"><i>780</i>&nbsp;            return ledgerInfo.getExplicitLac();</b>
<i>781</i>&nbsp;        }
<i>782</i>&nbsp;    }
<i>783</i>&nbsp;
<i>784</i>&nbsp;    private TransientLedgerInfo getOrAddLedgerInfo(long ledgerId) {
<b class="nc"><i>785</i>&nbsp;        TransientLedgerInfo tli = transientLedgerInfoCache.get(ledgerId);</b>
<b class="nc"><i>786</i>&nbsp;        if (tli != null) {</b>
<b class="nc"><i>787</i>&nbsp;            return tli;</b>
<i>788</i>&nbsp;        } else {
<b class="nc"><i>789</i>&nbsp;            TransientLedgerInfo newTli = new TransientLedgerInfo(ledgerId, ledgerIndex);</b>
<b class="nc"><i>790</i>&nbsp;            tli = transientLedgerInfoCache.putIfAbsent(ledgerId, newTli);</b>
<b class="nc"><i>791</i>&nbsp;            if (tli != null) {</b>
<b class="nc"><i>792</i>&nbsp;                newTli.close();</b>
<b class="nc"><i>793</i>&nbsp;                return tli;</b>
<i>794</i>&nbsp;            } else {
<b class="nc"><i>795</i>&nbsp;                return newTli;</b>
<i>796</i>&nbsp;            }
<i>797</i>&nbsp;        }
<i>798</i>&nbsp;    }
<i>799</i>&nbsp;
<i>800</i>&nbsp;    private void updateCachedLacIfNeeded(long ledgerId, long lac) {
<b class="nc"><i>801</i>&nbsp;        TransientLedgerInfo tli = transientLedgerInfoCache.get(ledgerId);</b>
<b class="nc"><i>802</i>&nbsp;        if (tli != null) {</b>
<b class="nc"><i>803</i>&nbsp;            tli.setLastAddConfirmed(lac);</b>
<i>804</i>&nbsp;        }
<b class="nc"><i>805</i>&nbsp;    }</b>
<i>806</i>&nbsp;
<i>807</i>&nbsp;    @Override
<i>808</i>&nbsp;    public void flushEntriesLocationsIndex() throws IOException {
<i>809</i>&nbsp;        // No-op. Location index is already flushed in updateEntriesLocations() call
<b class="nc"><i>810</i>&nbsp;    }</b>
<i>811</i>&nbsp;
<i>812</i>&nbsp;    /**
<i>813</i>&nbsp;     * Add an already existing ledger to the index.
<i>814</i>&nbsp;     *
<i>815</i>&nbsp;     * &lt;p&gt;This method is only used as a tool to help the migration from InterleaveLedgerStorage to DbLedgerStorage
<i>816</i>&nbsp;     *
<i>817</i>&nbsp;     * @param ledgerId
<i>818</i>&nbsp;     *            the ledger id
<i>819</i>&nbsp;     * @param pages
<i>820</i>&nbsp;     *            Iterator over index pages from Indexed
<i>821</i>&nbsp;     * @return the number of
<i>822</i>&nbsp;     */
<i>823</i>&nbsp;    public long addLedgerToIndex(long ledgerId, boolean isFenced, byte[] masterKey,
<i>824</i>&nbsp;            LedgerCache.PageEntriesIterable pages) throws Exception {
<b class="nc"><i>825</i>&nbsp;        LedgerData ledgerData = LedgerData.newBuilder().setExists(true).setFenced(isFenced)</b>
<b class="nc"><i>826</i>&nbsp;                .setMasterKey(ByteString.copyFrom(masterKey)).build();</b>
<b class="nc"><i>827</i>&nbsp;        ledgerIndex.set(ledgerId, ledgerData);</b>
<b class="nc"><i>828</i>&nbsp;        MutableLong numberOfEntries = new MutableLong();</b>
<i>829</i>&nbsp;
<i>830</i>&nbsp;        // Iterate over all the entries pages
<b class="nc"><i>831</i>&nbsp;        Batch batch = entryLocationIndex.newBatch();</b>
<b class="nc"><i>832</i>&nbsp;        for (LedgerCache.PageEntries page: pages) {</b>
<b class="nc"><i>833</i>&nbsp;            try (LedgerEntryPage lep = page.getLEP()) {</b>
<b class="nc"><i>834</i>&nbsp;                lep.getEntries((entryId, location) -&gt; {</b>
<b class="nc"><i>835</i>&nbsp;                    entryLocationIndex.addLocation(batch, ledgerId, entryId, location);</b>
<b class="nc"><i>836</i>&nbsp;                    numberOfEntries.increment();</b>
<b class="nc"><i>837</i>&nbsp;                    return true;</b>
<i>838</i>&nbsp;                });
<i>839</i>&nbsp;            }
<b class="nc"><i>840</i>&nbsp;        }</b>
<i>841</i>&nbsp;
<b class="nc"><i>842</i>&nbsp;        batch.flush();</b>
<b class="nc"><i>843</i>&nbsp;        batch.close();</b>
<i>844</i>&nbsp;
<b class="nc"><i>845</i>&nbsp;        return numberOfEntries.longValue();</b>
<i>846</i>&nbsp;    }
<i>847</i>&nbsp;
<i>848</i>&nbsp;    @Override
<i>849</i>&nbsp;    public void registerLedgerDeletionListener(LedgerDeletionListener listener) {
<b class="nc"><i>850</i>&nbsp;        ledgerDeletionListeners.add(listener);</b>
<b class="nc"><i>851</i>&nbsp;    }</b>
<i>852</i>&nbsp;
<i>853</i>&nbsp;    public EntryLocationIndex getEntryLocationIndex() {
<b class="nc"><i>854</i>&nbsp;        return entryLocationIndex;</b>
<i>855</i>&nbsp;    }
<i>856</i>&nbsp;
<i>857</i>&nbsp;    private void recordSuccessfulEvent(OpStatsLogger logger, long startTimeNanos) {
<b class="nc"><i>858</i>&nbsp;        logger.registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</b>
<b class="nc"><i>859</i>&nbsp;    }</b>
<i>860</i>&nbsp;
<i>861</i>&nbsp;    private void recordFailedEvent(OpStatsLogger logger, long startTimeNanos) {
<b class="nc"><i>862</i>&nbsp;        logger.registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</b>
<b class="nc"><i>863</i>&nbsp;    }</b>
<i>864</i>&nbsp;
<i>865</i>&nbsp;    long getWriteCacheSize() {
<b class="nc"><i>866</i>&nbsp;        return writeCache.size() + writeCacheBeingFlushed.size();</b>
<i>867</i>&nbsp;    }
<i>868</i>&nbsp;
<i>869</i>&nbsp;    long getWriteCacheCount() {
<b class="nc"><i>870</i>&nbsp;        return writeCache.count() + writeCacheBeingFlushed.count();</b>
<i>871</i>&nbsp;    }
<i>872</i>&nbsp;
<i>873</i>&nbsp;    long getReadCacheSize() {
<b class="nc"><i>874</i>&nbsp;        return readCache.size();</b>
<i>875</i>&nbsp;    }
<i>876</i>&nbsp;
<i>877</i>&nbsp;    long getReadCacheCount() {
<b class="nc"><i>878</i>&nbsp;        return readCache.count();</b>
<i>879</i>&nbsp;    }
<i>880</i>&nbsp;
<i>881</i>&nbsp;    @Override
<i>882</i>&nbsp;    public List&lt;GarbageCollectionStatus&gt; getGarbageCollectionStatus() {
<b class="nc"><i>883</i>&nbsp;        return Collections.singletonList(gcThread.getGarbageCollectionStatus());</b>
<i>884</i>&nbsp;    }
<i>885</i>&nbsp;
<i>886</i>&nbsp;    /**
<i>887</i>&nbsp;     * Interface which process ledger logger.
<i>888</i>&nbsp;     */
<i>889</i>&nbsp;    public interface LedgerLoggerProcessor {
<i>890</i>&nbsp;        void process(long entryId, long entryLogId, long position);
<i>891</i>&nbsp;    }
<i>892</i>&nbsp;
<b class="nc"><i>893</i>&nbsp;    private static final Logger log = LoggerFactory.getLogger(SingleDirectoryDbLedgerStorage.class);</b>
<i>894</i>&nbsp;
<i>895</i>&nbsp;    @Override
<i>896</i>&nbsp;    public OfLong getListOfEntriesOfLedger(long ledgerId) throws IOException {
<b class="nc"><i>897</i>&nbsp;        throw new UnsupportedOperationException(</b>
<i>898</i>&nbsp;                &quot;getListOfEntriesOfLedger method is currently unsupported for SingleDirectoryDbLedgerStorage&quot;);
<i>899</i>&nbsp;    }
<i>900</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2021-06-29 13:53</div>
</div>
</body>
</html>
